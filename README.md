# TVM
Optimizing YOLOv8 with Apache TVM for Efficient CPU Inference This project demonstrates how to export, quantize, compile, and benchmark YOLOv8n using the Apache TVM AI compiler â€” enabling faster, lighter, and hardware-agnostic inference.
